{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "40f71218",
   "metadata": {},
   "source": [
    "# CS229, Fall 2017\n",
    "## Problem Set 1: Supervised Learning\n",
    "\n",
    "This is my solutions for CS229 - Fall 2017: Machine Learning taught by Andrew Ng.\n",
    "\n",
    "The material for Problem Set 1 is here: [ps1](https://github.com/nmduonggg/ML-CS229/blob/master/Problem%20Set%201/ps1.pdf)\n",
    "\n",
    "This notebook contains the solution for __Question 3: Gausian Discirminant Analysis__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33eab82b",
   "metadata": {},
   "source": [
    "### Notation\n",
    "* $x^i$: $i^{th}$ instances of the dataset\n",
    "* $y^i$: $i^{th}$ target value of the dataset\n",
    "* $x_j^i$: the $j^{th}$ feature of the $i^{th}$ instance\n",
    "* $\\theta_j$: coefficient corresponding to the $j^{th}$ feature\n",
    "* $h_{\\theta}$: an approximation of our model\n",
    "* $m$: number of training instances\n",
    "* $n$: number of features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "924ea664",
   "metadata": {},
   "source": [
    "### Question 3.a)\n",
    "\n",
    "Suppose we have already fit $\\phi, \\Sigma, \\mu_{-1}, \\mu_1$, and now want to make a prediction at some new query point $x$. Show that the posterior distribution of the label at $x$ takes the form of a logistic function, can be written:\n",
    "$$\n",
    "\\begin{align*}\n",
    "p(y=1|x; \\phi, \\Sigma, \\mu_{-1}, \\mu_1) &= \\frac{p(x|y=1; \\mu_1, \\Sigma)p(y=1; \\phi)}{p(x|y=1; \\mu_1, \\Sigma)p(y=1; \\Sigma) + p(x|y = -1; \\mu_{-1}, \\Sigma)p(y = -1; \\phi)} \\\\ \\\\\n",
    "    &= \\frac{\\frac{\\phi}{(2\\pi)^{n/2}|\\Sigma|^{1/2}}exp\\big((\\frac{-1}{2}(x - \\mu_1)^T\\Sigma^{-1}(x -\\mu_1)\\big)}{\\frac{\\phi}{(2\\pi)^{n/2}|\\Sigma|^{1/2}}exp\\big(\\frac{-1}{2}(x - \\mu_1)^T\\Sigma^{-1}(x -\\mu_1)\\big) + \\frac{1-\\phi}{(2\\pi)^{n/2}|\\Sigma|^{1/2}}exp\\big(\\frac{-1}{2}(x - \\mu_{-1})^T\\Sigma^{-1}(x -\\mu_{-1})\\big)} \\\\ \\\\\n",
    "    &= \\frac{1}{1+ exp\\big(log(\\frac{1 - \\phi}{\\phi}) + \\frac{-1}{2}(x - \\mu_{-1})^T\\Sigma^{-1}(x-\\mu_{-1}) - \\frac{-1}{2}(x-\\mu_1)^T\\Sigma^{-1}(x - \\mu_1)\\big)} \\\\ \\\\\n",
    "    &= \\frac{1}{1 + exp\\big(log(\\frac{1-\\phi}{\\phi}) + \\frac{-1}{2}(x^T\\Sigma^{-1}x - 2x^T\\Sigma^{-1}\\mu_{-1} + \\mu_{-1}^T\\Sigma^{-1}\\mu_{-1} - x^T\\Sigma^{-1}x + 2x^T\\Sigma^{-1}\\mu_{1} - \\mu_{1}^T\\Sigma^{-1}\\mu_{1})\\big)} \\\\ \\\\\n",
    "    &= \\frac{1}{1 + exp\\big(log(\\frac{1-\\phi}{\\phi}) + \\frac{-1}{2}(2x^T\\Sigma^{-1}\\mu_1 - 2x^T\\Sigma^{-1}\\mu_{-1} + \\mu_{-1}^T\\Sigma^{-1}\\mu_{-1} - \\mu_{1}^T\\Sigma^{-1}\\mu_{1})\\big)} \\\\ \\\\\n",
    "    &= \\frac{1}{1 + exp\\big(-1\\big((x^T(\\Sigma^{-1}\\mu_{1} - \\Sigma^{-1}\\mu_{-1}) + \\frac{1}{2} \\mu_{-1}^T\\Sigma^{-1}\\mu_{-1} - \\frac{1}{2} \\mu_{1}^T\\Sigma^{-1}\\mu_{1} - log(\\frac{1-\\phi}{\\phi}) \\big)} \\\\ \\\\\n",
    "\\end{align*}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8e95978",
   "metadata": {},
   "source": [
    "Let's reassign our parameters as follows:\n",
    "* $\\theta = \\Sigma^{-1} (\\mu_{1} - \\mu_{-1})$\n",
    "* $\\theta_0 = \\frac{1}{2}\\big(\\mu_{-1}^T\\Sigma^{-1}\\mu_{-1} - \\mu_1^T\\Sigma^{-1}\\mu_1 \\big) - log(\\frac{1-\\phi}{\\phi})$\n",
    "\n",
    "Also, since the new input $x = (x_1, x_2,..., x_n)$ and $\\theta = (\\theta_1, \\theta_2,..., \\theta_n)$, under this scenerio, we can assume that $x^T\\theta = \\theta^Tx$. This assumption leads to the following:\n",
    "\n",
    "$$p(y=1|x; \\phi, \\Sigma, \\mu_{-1}, \\mu_1) = \\frac{1}{1 + exp\\big(-y(\\theta^Tx + \\theta_0)\\big)}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e41e78e",
   "metadata": {},
   "source": [
    "### Question 3.bc)\n",
    "\n",
    "The log-likelihood function:\n",
    "\n",
    "$$\n",
    "\\begin{align*}\n",
    "l(\\phi, \\Sigma, \\mu_{-1}, \\mu_1) &= log \\prod_{i=1}^m p(x^i, y^i; \\phi, \\Sigma, \\mu_{-1}, \\mu_1) \\\\\n",
    "    &= \\sum_{i=1}^m log\\big(p(x^i|y^i; \\Sigma, \\mu_{-1}, \\mu_1)p(y;\\phi)\\big) \\\\\n",
    "\\end{align*}\n",
    "$$\n",
    "\n",
    "#### Question 3.bc.1) Prove \n",
    "$$\\phi = \\frac{1}{m} \\sum_{i=1}^m 1\\{y^i - 1\\}$$\n",
    "\n",
    "\n",
    "Consider log-likelihood as a function of $\\phi$, then in order to maximize it, $\\frac{\\partial}{\\partial \\phi} l(\\phi, \\Sigma, \\mu_{-1}, \\mu_1) = 0$, which indicates the followings:\n",
    "\n",
    "$$\n",
    "\\begin{align*}\n",
    "\\frac{\\partial}{\\partial \\phi} l(\\phi, \\Sigma, \\mu_{-1}, \\mu_1) &= \\frac{\\partial}{\\partial \\phi} \\sum_{i=1}^m log\\big(p(x^i | y^i; \\Sigma, \\mu_{-1}, \\mu_1)\\big) + log(p(y; \\phi)) \\\\ \\\\\n",
    "    &= \\sum_{i=1}^m  \\frac{\\partial}{\\partial \\phi}log(p(y^i; \\phi) \\\\ \\\\\n",
    "    &= \\sum_{i=1}^m \\frac{1}{p(y^i; \\phi)}\\frac{\\partial}{\\partial \\phi}p(y^i; \\phi)\n",
    "\\end{align*}\n",
    "$$\n",
    "\n",
    "To discuss more about our probability of $y = p(y; \\phi)$,\n",
    "$$\n",
    "    f(x)= \n",
    "\\begin{cases}\n",
    "    \\phi,& \\text{if } y = 1 \\\\\n",
    "    1- \\phi,              & \\text{if } y = -1\n",
    "\\end{cases}\n",
    "$$\n",
    "\n",
    "\n",
    "\n",
    "we can convert it into the following function:\n",
    "\n",
    "$$ p(y ; \\phi) = \\phi^{\\frac{1}{2}y + \\frac{1}{2}}(1-\\phi)^{\\frac{-1}{2}y + \\frac{1}{2}}$$\n",
    "\n",
    "We care only the function of $\\phi$ then consider\n",
    "\n",
    "$$\n",
    "\\begin{align*}\n",
    "\\frac{\\partial}{\\partial \\phi} l(\\phi, \\Sigma, \\mu_{-1}, \\mu_1) &= \\sum_{i=1}^m \\frac{1}{p(y^i; \\phi)} \\frac{\\partial}{\\partial \\phi} p(y^i; \\phi) \\\\ \\\\\n",
    "    &= \\sum_{i=1}^m \\frac{1}{\\phi^{\\frac{1}{2}y^i + \\frac{1}{2}}(1 - \\phi)^{\\frac{-1}{2}y^i + \\frac{1}{2}}} \\ \\frac{\\partial}{\\partial \\phi} \\phi^{\\frac{1}{2}y^i + \\frac{1}{2}}(1 - \\phi)^{\\frac{-1}{2}y^i + \\frac{1}{2}} \\\\ \\\\\n",
    "    &= \\frac{1}{2} \\sum_{i=1}^m \\frac{y^i + 1 -2\\phi}{\\phi(1-\\phi)}\n",
    "\\end{align*}\n",
    "$$\n",
    "\n",
    "Assumption $\\frac{\\partial}{\\partial \\phi} l(\\phi, \\Sigma, \\mu_{-1}, \\mu_1) = 0$ leads to:\n",
    "\n",
    "$$\\sum_{i=1}^m \\phi = \\sum_{i=1}^m \\frac{y^i + 1}{2} \\\\\n",
    "\\implies m\\phi = \\sum_{i=1}^m 1\\{y^i = 1\\} \\\\\n",
    "\\implies \\phi = \\frac{1}{m} \\sum_{i=1}^m 1\\{y^i - 1\\} \n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f73b477",
   "metadata": {},
   "source": [
    "#### Question 3.bc.2) Prove\n",
    "\n",
    "$$\\mu_1 = \\frac{\\sum_{i=1}^m 1\\{y^i = 1\\}x^i}{\\sum_{i=1}^m 1\\{y^i = 1\\}}$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31b698d1",
   "metadata": {},
   "source": [
    "Firstly, for general case, we have:\n",
    "\n",
    "$$\n",
    "\\begin{align*}\n",
    "\\nabla_{\\mu_y^i} l(x^i, y^i; \\Sigma, \\mu_{y^i}, \\phi) &= \\sum_{i=1}^m \\frac{\\partial}{\\partial \\mu_{y^i}} \\bigg( log \\big(p(x^i|y^i; \\Sigma, \\mu_{y^i})\\big) + log \\big(p(y^i; \\phi) \\big) \\bigg) \\\\ \\\\\n",
    "    &= \\sum_{i=1}^m \\frac{\\partial}{\\partial \\mu_{y^i}} log p(x^i | y^i ;\\Sigma, \\mu_{y^i}) \\\\ \\\\ \n",
    "    &= \\sum_{i=1}^m \\frac{\\partial}{\\partial \\mu_{y^i}} log(\\frac{1}{(2\\pi)^{n/2} |\\Sigma|^{\\frac{1}{2}}}) + \\frac{-1}{2}(x - \\mu_{y^i})^T \\Sigma^{-1} (x - \\mu_{y^i}) \\\\ \\\\\n",
    "    &= \\frac{-1}{2} \\sum_{i=1}^m  \\frac{\\partial}{\\partial \\mu_{y^i}} (x^T \\Sigma^{-1}x - 2x^T \\Sigma^{-1} \\mu_{y^i} + \\mu_{y^i}^T \\Sigma^{-1} \\mu_{y^i}) \\\\ \\\\\n",
    "    &= \\frac{-1}{2} \\sum_{i=1}^m -2x^i\\Sigma^{-1} + 2\\mu_{y^i}\\Sigma^{-1} \\\\ \\\\\n",
    "    &= \\sum_{i=1}^m x^i\\Sigma^{-1} - \\mu_{y^i}\\Sigma^{-1}\n",
    "\\end{align*}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "701d9dde",
   "metadata": {},
   "source": [
    "For $\\mu_1$, we have:\n",
    "$$\\nabla_{\\mu_1} l(x^i, y^i; \\Sigma, \\mu_1, \\phi) = \\sum_{i=1 \\land y^i = 1}^m x^i\\Sigma^{-1} - \\sum_{i=1 \\land y^i = 1}^m \\mu_1\\Sigma^{-1} = 0 \\\\\n",
    "\\implies  \\sum_{i = 1 \\land y^i = 1}^m \\mu_1\\Sigma^{-1} = \\sum_{i=1 \\land y^i = 1}^m x^i\\Sigma^{-1} \\\\\n",
    "\\implies \\mu_1 = \\frac{\\sum_{i=1}^m 1\\{y^i = 1\\}x^i}{\\sum_{i=1}^m 1\\{y^i = 1\\}}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c637c592",
   "metadata": {},
   "source": [
    "Similarly, we can easily estimate $\\mu_{-1}$ as follows:\n",
    "$$\\mu_{-1} = \\frac{\\sum_{i=1}^m 1\\{y^i = -1\\}x^i}{\\sum_{i=1}^m 1\\{y^i = -1\\}}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20994db7",
   "metadata": {},
   "source": [
    "#### Question 3.b.3) Prove \n",
    "$$\\Sigma =  \\frac{1}{m} \\sum_{i=1}^m (x^i - \\mu_{y^i})(x^i - \\mu_{y^i})^T$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fc72667",
   "metadata": {},
   "source": [
    "First thing I have to remind is $\\Sigma$ is a __real number__  since dimension $n = 1$, then $\\Sigma^{-1} = \\frac{1}{\\Sigma}$. (I do not know how to convert $\\frac{1}{|\\Sigma|}$ and $\\Sigma$ for question 3.c) then I will only try to solve 3.b.3)).\n",
    "\n",
    "Let $V = \\frac{1}{\\Sigma}$, then:\n",
    "\n",
    "$$\n",
    "\\begin{align*}\n",
    "\\nabla_V l(x^i, y^i; \\Sigma, \\mu_{y^i}, \\phi) &= \\frac{-1}{2} \\sum_{i=1}^m \\frac{\\partial}{\\partial V} \\bigg[ (x^TVx - 2x^T V \\mu_{y^i} + \\mu_{y^i}^T V \\mu_{y^i}) \\bigg] + \\sum_{i=1}^m \\frac{\\partial}{\\partial V} \\bigg[ log(\\frac{1}{(2\\pi)^{n/2} V^{\\frac{-1}{2}}}) \\bigg] \\\\ \\\\\n",
    "    &= \\frac{-1}{2} \\sum_{i=1}^m (x^i)^2 - 2x^i\\mu_{y^i} + \\mu_{y^i}^2 + \\sum_{i=1}^m \\frac{1}{2V} \\\\ \\\\\n",
    "    &= \\frac{-1}{2} \\sum_{i=1}^m (x^i - \\mu_{y^i})^2 + \\sum_{i=1}^m \\frac{1}{2V}\n",
    "\\end{align*}\n",
    "$$\n",
    "Let's gradient of V is 0 then:\n",
    "$$\\sum_{i=1}^m \\frac{1}{2V} = \\frac{1}{2} \\sum_{i=1}^m (x^i - \\mu_{y^i})^2 \\\\\n",
    "\\implies m\\Sigma = \\sum_{i=1}^m (x^i - \\mu_{y^i})(x^i - \\mu_{y^i})^T \\\\\n",
    "\\implies \\Sigma = \\frac{1}{m} \\sum_{i=1}^m (x^i - \\mu_{y^i})(x^i - \\mu_{y^i})^T\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d693ffc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
