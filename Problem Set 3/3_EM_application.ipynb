{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "096a76bf",
   "metadata": {},
   "source": [
    "# CS229, Fall 2017\n",
    "## Problem Set 3: Deep Learning & Unsupervised Learning\n",
    "\n",
    "This is my solutions for CS229 - Fall 2017: Machine Learning taught by Andrew Ng.\n",
    "\n",
    "The material for Problem Set 3 is here: [ps3](https://github.com/nmduonggg/ML-CS229/blob/master/Problem%20Set%203/ps3.pdf)\n",
    "\n",
    "This notebook contains the solution for __Question 3: EM Application__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c83646a6",
   "metadata": {},
   "source": [
    "### Question 3.i.a)\n",
    "From statement given that:\n",
    "\n",
    "$$y \\sim N\\big(\\mu_p, \\sigma_p^2\\big) \\\\ z \\sim N\\big(\\nu_r, \\tau_r^2\\big) \\\\ \\epsilon \\sim N\\big(0, \\sigma^2\\big)$$\n",
    "\n",
    "$x^{(pr)}$ can be written as:\n",
    "\n",
    "$$x^{(pr)} = y^{(pr)} + z^{(pr)} + \\epsilon^{(pr)}$$\n",
    "\n",
    "where $x^{(pr)}, y^{(pr)}, z^{(pr)}, \\epsilon^{(pr)}$ are jointly independent. The joint distribution of $x, y, z$ should be:\n",
    "\n",
    "$$\n",
    "\\begin{bmatrix}\n",
    "    x \\\\ y \\\\ z\n",
    "\\end{bmatrix}\n",
    "= N \\bigg(\n",
    "\\begin{bmatrix}\n",
    "    \\mu_x \\\\ \\mu_y \\\\ \\mu_z\n",
    "\\end{bmatrix},\n",
    "\\begin{bmatrix}\n",
    "    \\sigma_{xx} & \\sigma_{xy} & \\sigma_{xz} \\\\\n",
    "    \\sigma_{yx} & \\sigma_{yy} & \\sigma_{yz} \\\\\n",
    "    \\sigma_{zx} & \\sigma_{zy} & \\sigma_{zz} \\\\\n",
    "\\end{bmatrix} \\bigg)\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fb4b300",
   "metadata": {},
   "source": [
    "Mean of $x^{(pr)}$:\n",
    "\n",
    "$$E[x] = E[y + z + \\epsilon] = E[y] + E[z] + E[\\epsilon] = \\mu_p + \\nu_r$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b61cfdfa",
   "metadata": {},
   "source": [
    "To clarify covariance matrix:\n",
    "\n",
    "$$\n",
    "\\begin{align*}\n",
    "\\sigma_{xy} &= E \\big[(x - \\mu_x)(y - \\mu_y)\\big] \\\\\n",
    "    &= E \\big[ (y + z + \\epsilon - \\mu_p - \\nu_r ) (y - \\mu_p ) \\big] \\\\\n",
    "    &= E [y^2] - \\mu_p^2 \\\\\n",
    "    &= \\sigma_p^2\n",
    "\\end{align*}\n",
    "$$\n",
    "\n",
    "Similarly, it is straightforward to see that $\\sigma_{xz} = \\tau^2_r$ and $\\sigma_{yz} = 0$ since $y, z$ are independent"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3759d15",
   "metadata": {},
   "source": [
    "Also, \n",
    "\n",
    "$$\n",
    "\\begin{align*}\n",
    "    \\sigma_{xx} &= E[x^2] - E[x]^2 \\\\\n",
    "        &= E\\big[(y + z + \\epsilon)^2\\big] - (\\mu_p + \\nu_r)^2 \\\\\n",
    "        &= E\\big[y^2 + z^2 + \\epsilon^2 + 2yz + 2y\\epsilon + 2z\\epsilon\\big] - (\\mu_p + \\nu_r)^2 \\\\\n",
    "        &= E[y^2] + E[z^2] + E[\\epsilon^2] - \\mu_p^2 - \\nu_r^2 \\\\\n",
    "        &= \\sigma_p^2 + \\tau_r^2 + \\sigma^2\n",
    "\\end{align*}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56579b2e",
   "metadata": {},
   "source": [
    "Then the __joint distribution__ is:\n",
    "\n",
    "$$\n",
    "\\begin{bmatrix}\n",
    "    x \\\\ y \\\\ z\n",
    "\\end{bmatrix}\n",
    "= N \\bigg(\n",
    "\\begin{bmatrix}\n",
    "    \\mu_p + \\nu_r \\\\ \\mu_p \\\\ \\nu_r\n",
    "\\end{bmatrix},\n",
    "\\begin{bmatrix}\n",
    "    \\sigma_p^2 + \\tau_r^2 + \\sigma^2 & \\sigma_p^2 & \\tau_r^2 \\\\\n",
    "    \\sigma_p^2 & \\sigma_p^2 & 0 \\\\\n",
    "    \\tau_r^2 & 0 & \\tau_r^2 \\\\\n",
    "\\end{bmatrix} \\bigg)\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b8572cf",
   "metadata": {},
   "source": [
    "### Question 3.i.b)\n",
    "\n",
    "Since we are consider subset $w = [y, z]& to be conditioning on $x$, the joint distribution can be rewritten:\n",
    "\n",
    "$$\n",
    "\\begin{bmatrix}\n",
    "    x \\\\ w\n",
    "\\end{bmatrix}\n",
    "= N \\bigg(\n",
    "\\begin{bmatrix}\n",
    "    \\mu_x \\\\ \\mu_w\n",
    "\\end{bmatrix},\n",
    "\\begin{bmatrix}\n",
    "    \\Sigma_{xx} & \\Sigma_{xw} \\\\\n",
    "    \\Sigma_{wx} & \\Sigma_{ww} \\\\\n",
    "\\end{bmatrix} \\bigg)\n",
    "$$\n",
    "\n",
    "where:\n",
    "\n",
    "$$\n",
    "\\Sigma_{xx} = [\\sigma_p^2 + \\tau_r^2 + \\sigma^2] \\\\ \\\\\n",
    "\\Sigma_{xw} = \\Sigma_{wx}^T = [\\sigma_p^2 \\quad \\tau_r^2] \\\\ \\\\\n",
    "\\Sigma_{ww} = \n",
    "\\begin{bmatrix}\n",
    "    \\sigma_p^2 & 0 \\\\\n",
    "    0 & \\tau_p^2\n",
    "\\end{bmatrix}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf15240a",
   "metadata": {},
   "source": [
    "Therefore,\n",
    "\n",
    "$$w^{(pr)} | x^{(pr)} \\sim N\\big(\\mu_{w|x}, \\Sigma_{w|x}\\big) $$\n",
    "\n",
    "where:\n",
    "\n",
    "$$\n",
    "\\mu_{w|x} = \\mu_w + \\Sigma_{wx} \\Sigma_{xx}^{-1} (w - \\mu_w) \\\\\n",
    "\\Sigma_{w|x} = \\Sigma_{ww} - \\Sigma_{wx}\\Sigma_{xx}^{-1}\\Sigma_{xw}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af857aed",
   "metadata": {},
   "source": [
    "For __E-step__:\n",
    "$$\n",
    "Q_{pr}(w) = \\frac{1}{2\\pi |\\Sigma_{w|x}|^{\\frac{1}{2}}} exp\\bigg[-\\frac{1}{2} \\big(w - \\mu_{w|x}) \\Sigma_{w|x}^{-1} (w - \\mu_{w|x})^T\\bigg]\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d5196c4",
   "metadata": {},
   "source": [
    "### Question 3.ii)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "547d6a70",
   "metadata": {},
   "source": [
    "$$\n",
    "\\begin{align*}\n",
    "\\text{maximize} \\quad &\\sum_p \\sum_r \\int_{w} Q_{pr}(w) \\frac{\\log \\big(p(w, x; \\mu_p, \\sigma_p, \\nu_r, \\tau_r) \\big)}{Q_{pr}(w)} \\\\\n",
    "    &= \\sum_p \\sum_r E_{w \\sim Q_{pr}}\\bigg[ \\frac{\\log \\big(p(w, x; \\mu_p, \\sigma_p, \\nu_r, \\tau_r) \\big)}{Q_{pr}(w)}\\bigg] \\\\\n",
    "    &= \\sum_p \\sum_r E_{w \\sim Q_{pr}}\\bigg[ \\log p(x |w; \\mu_p, \\sigma_p, \\nu_r, \\tau_r) + \\log p(w) - \\log Q_{pr}(w) \\bigg]\n",
    "\\end{align*}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01651ad4",
   "metadata": {},
   "source": [
    "In M-step, derive the gradient ascent for the above MLE equation and converges to the optimal parameters."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
